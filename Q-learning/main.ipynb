{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import importlib\n",
    "import q_learning\n",
    "importlib.reload(q_learning)\n",
    "from q_learning import run\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Q_learning tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "is_training = [True]\n",
    "is_slippery = [False, True]\n",
    "n_episodes = [15000]\n",
    "map_names = ['4x4', '8x8', '9x9', '10x10']\n",
    "seed = [20] #20 works for 4 and 8, 16 and 32 are too big\n",
    "learning_rate_as = [0.01, 0.1, 0.9] #0.1, 0.01, 0.5 works\n",
    "discount_factor_gammas = [0.01, 0.5, 0.95] #0.1, 0.5, 0.95 works\n",
    "epsilon = [1]\n",
    "epsilon_decay_rates = [0.0001]\n",
    "render = [False]\n",
    "hyperparameter_grid = list(product(is_training, render, is_slippery, n_episodes, map_names, seed, learning_rate_as, discount_factor_gammas, epsilon, epsilon_decay_rates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "num_hyper = len(hyperparameter_grid)\n",
    "print(f\"Running {num_hyper} hyperparameter combinations\")\n",
    "\n",
    "for hyperparameters in hyperparameter_grid:\n",
    "    is_training, render, is_slippery, n_episodes, map_name, seed, learning_rate_a, discount_factor_gamma, epsilon, epsilon_decay_rate = hyperparameters\n",
    "    rewards_per_episode = run(is_training=is_training, render=render, is_slippery=is_slippery, episodes=n_episodes, map_name=map_name, seed=seed, learning_rate_a=learning_rate_a, discount_factor_g=discount_factor_gamma, epsilon=epsilon, epsilon_decay_rate=epsilon_decay_rate)\n",
    "    results.append({\"is_training\": is_training, \"render\": render, \"is_slippery\": is_slippery, \"n_episodes\": n_episodes, \"map_name\": map_name, \"seed\": seed, \"learning_rate_a\": learning_rate_a, \"discount_factor_gamma\": discount_factor_gamma, \"epsilon\": epsilon, \"epsilon_decay_rate\": epsilon_decay_rate, \"rewards_per_episode\": rewards_per_episode})\n",
    "    print(f\"{len(results)/num_hyper*100}% done\")\n",
    "    \n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sum_rewards(rewards_per_episode):\n",
    "    sum_rewards = np.zeros(rewards_per_episode.shape[0])\n",
    "    for t in range(rewards_per_episode.shape[0]):\n",
    "        sum_rewards[t] = np.sum(rewards_per_episode[max(0, t-100):(t+1)])\n",
    "        \n",
    "    return sum_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sum_rewards'] = df['rewards_per_episode'].apply(calc_sum_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save df to csv\n",
    "import csv\n",
    "df.to_csv('./results/frozen_lake_results.csv', index=False, quoting=csv.QUOTE_NONE)\n",
    "df.to_pickle('./results/frozen_lake_results.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
